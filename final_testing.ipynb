{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from joblib import load\n",
    "from sklearn.metrics import classification_report , matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('processed.cleveland.data' , header=None)\n",
    "all_columns = ['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','target']\n",
    "df.columns = all_columns\n",
    "df = df[~df.isin(['?']).any(axis=1)]\n",
    "\n",
    "true_labels = df['target'].values\n",
    "input_columns = df.columns.drop('target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_models = {\n",
    "    'binary': load('raw_models/model_binary.pkl'),\n",
    "    '14_23': load('raw_models/model_14_23.pkl'),\n",
    "    '1_4': load('raw_models/model_1_4.pkl'),\n",
    "    '2_3': load('raw_models/model_2_3.pkl'),\n",
    "}\n",
    "\n",
    "raw_scalers = {\n",
    "    'binary': load('raw_scaler/scaler_binary.pkl'),\n",
    "    '14_23': load('raw_scaler/scaler_14_23.pkl'),\n",
    "    '1_4': load('raw_scaler/scaler_1_4.pkl'),\n",
    "    '2_3': load('raw_scaler/scaler_2_3.pkl'),\n",
    "}\n",
    "\n",
    "raw_features_dict = {\n",
    "    'binary': ['thal', 'exang', 'thalach', 'ca', 'chol', 'slope', 'fbs', 'sex', 'restecg', 'age', 'oldpeak'],\n",
    "    '1_4': ['sex', 'slope', 'fbs', 'thalach', 'trestbps', 'restecg', 'thal', 'cp', 'oldpeak', 'exang'],\n",
    "    '2_3': ['trestbps', 'slope', 'oldpeak'],\n",
    "    '14_23': ['trestbps', 'slope', 'restecg', 'sex', 'fbs', 'thal', 'age', 'oldpeak'],\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_models = {\n",
    "    'binary': load('smote_models/model_binary.pkl'),\n",
    "    '14_23': load('smote_models/model_14_23.pkl'),\n",
    "    '1_4': load('smote_models/model_1_4.pkl'),\n",
    "    '2_3': load('smote_models/model_2_3.pkl'),\n",
    "}\n",
    "\n",
    "smote_scalers = {\n",
    "    'binary': load('smote_scaler/scaler_binary.pkl'),\n",
    "    '14_23': load('smote_scaler/scaler_14_23.pkl'),\n",
    "    '1_4': load('smote_scaler/scaler_1_4.pkl'),\n",
    "    '2_3': load('smote_scaler/scaler_2_3.pkl'),\n",
    "}\n",
    "\n",
    "smote_features_dict = {\n",
    "    'binary': ['fbs', 'slope', 'ca', 'restecg', 'exang', 'sex', 'thalach', 'chol'],\n",
    "    '1_4': ['chol', 'fbs', 'thal', 'restecg', 'ca', 'sex', 'exang', 'age', 'oldpeak','trestbps', 'thalach', 'cp', 'slope'],\n",
    "    '2_3': ['oldpeak', 'thal', 'cp', 'fbs', 'chol', 'age', 'ca', 'sex','slope', 'trestbps', 'restecg'],\n",
    "    '14_23': ['ca', 'cp', 'slope', 'fbs', 'age', 'restecg', 'trestbps'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adasyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.5.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "adasyn_models = {\n",
    "    'binary': load('adasyn_models/model_binary.pkl'),\n",
    "    '14_23': load('adasyn_models/model_14_23.pkl'),\n",
    "    '1_4': load('adasyn_models/model_1_4.pkl'),\n",
    "    '2_3': load('adasyn_models/model_2_3.pkl'),\n",
    "}\n",
    "\n",
    "adasyn_scalers = {\n",
    "    'binary': load('adasyn_scaler/scaler_binary.pkl'),\n",
    "    '14_23': load('adasyn_scaler/scaler_14_23.pkl'),\n",
    "    '1_4': load('adasyn_scaler/scaler_1_4.pkl'),\n",
    "    '2_3': load('adasyn_scaler/scaler_2_3.pkl'),\n",
    "}\n",
    "\n",
    "adasyn_features_dict = {\n",
    "    'binary': ['slope', 'thalach', 'chol', 'ca', 'restecg', 'fbs', 'sex', 'age', 'exang'],\n",
    "    '1_4': ['slope', 'oldpeak', 'restecg', 'age', 'trestbps', 'cp', 'fbs'],\n",
    "    '2_3': ['oldpeak', 'sex', 'fbs', 'slope', 'restecg', 'trestbps', 'age'],\n",
    "    '14_23': ['ca', 'chol', 'oldpeak', 'trestbps', 'thal', 'fbs', 'restecg', 'age', 'cp', 'exang', 'slope'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smote Tomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_tomek_models = {\n",
    "    'binary': load('smote_tomek_models/model_binary.pkl'),\n",
    "    '14_23': load('smote_tomek_models/model_14_23.pkl'),\n",
    "    '1_4': load('smote_tomek_models/model_1_4.pkl'),\n",
    "    '2_3': load('smote_tomek_models/model_2_3.pkl'),\n",
    "}\n",
    "\n",
    "smote_tomek_scalers = {\n",
    "    'binary': load('smote_tomek_scaler/scaler_binary.pkl'),\n",
    "    '14_23': load('smote_tomek_scaler/scaler_14_23.pkl'),\n",
    "    '1_4': load('smote_tomek_scaler/scaler_1_4.pkl'),\n",
    "    '2_3': load('smote_tomek_scaler/scaler_2_3.pkl'),\n",
    "}\n",
    "\n",
    "smote_tomek_features_dict = {\n",
    "    'binary': ['thalach', 'sex', 'fbs', 'exang', 'restecg', 'oldpeak'],\n",
    "    '1_4': ['trestbps', 'cp', 'ca', 'oldpeak', 'chol', 'slope', 'thal', 'exang'],\n",
    "    '2_3': ['exang', 'restecg', 'trestbps', 'slope'],\n",
    "    '14_23': ['chol', 'cp', 'exang', 'thal', 'age', 'oldpeak', 'fbs', 'slope', 'sex', 'ca', 'trestbps', 'thalach'],\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kmeans Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_smote_models = {\n",
    "    'binary': load('kmeans_smote_models/model_binary.pkl'),\n",
    "    '14_23': load('kmeans_smote_models/model_14_23.pkl'),\n",
    "    '1_4': load('kmeans_smote_models/model_1_4.pkl'),\n",
    "    '2_3': load('kmeans_smote_models/model_2_3.pkl'),\n",
    "}\n",
    "\n",
    "kmeans_smote_scalers = {\n",
    "    'binary': load('kmeans_smote_scaler/scaler_binary.pkl'),\n",
    "    '14_23': load('kmeans_smote_scaler/scaler_14_23.pkl'),\n",
    "    '1_4': load('kmeans_smote_scaler/scaler_1_4.pkl'),\n",
    "    '2_3': load('kmeans_smote_scaler/scaler_2_3.pkl'),\n",
    "}\n",
    "\n",
    "kmeans_smote_features_dict = {\n",
    "    'binary': ['age', 'ca', 'sex', 'exang', 'thalach', 'restecg', 'chol', 'thal'],\n",
    "    '1_4': ['oldpeak', 'fbs', 'age', 'thalach', 'restecg', 'trestbps', 'exang', 'ca', 'cp', 'chol'],\n",
    "    '2_3': ['slope', 'restecg', 'fbs', 'trestbps'],\n",
    "    '14_23': ['ca', 'cp', 'fbs', 'chol', 'restecg', 'thal', 'oldpeak', 'trestbps', 'exang', 'slope', 'age', 'thalach', 'sex'],\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_all(df, models, scalers, features_dict, input_columns, heuristics=[1] * 8):\n",
    "    final_predictions = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        full_row = row[input_columns].to_frame().T\n",
    "\n",
    "        scaled = pd.DataFrame(\n",
    "            scalers[\"binary\"].transform(full_row), columns=input_columns\n",
    "        )\n",
    "        bin_pred = models[\"binary\"].predict_proba(scaled[features_dict[\"binary\"]])[0]\n",
    "\n",
    "        if bin_pred[0] * heuristics[0] > bin_pred[1] * heuristics[1]:\n",
    "            final_predictions.append(0)\n",
    "        else:\n",
    "            # 14 vs 23\n",
    "            scaled = pd.DataFrame(scalers[\"14_23\"].transform(full_row), columns=input_columns)\n",
    "            pred_14_23 = models[\"14_23\"].predict_proba(scaled[features_dict[\"14_23\"]])[0]\n",
    "\n",
    "            if pred_14_23[0] * heuristics[2] > pred_14_23[1] * heuristics[3]:\n",
    "\n",
    "                scaled = pd.DataFrame(scalers[\"1_4\"].transform(full_row), columns=input_columns)\n",
    "                pred_1_4 = models[\"1_4\"].predict_proba(scaled[features_dict[\"1_4\"]])[0]\n",
    "                final_predictions.append(1 if pred_1_4[0] * heuristics[4] > pred_1_4[1] * heuristics[5] else 4)\n",
    "            else:\n",
    "                # 2 vs 3\n",
    "                scaled = pd.DataFrame(\n",
    "                    scalers[\"2_3\"].transform(full_row), columns=input_columns\n",
    "                )\n",
    "                pred_2_3 = models[\"2_3\"].predict_proba(scaled[features_dict[\"2_3\"]])[0]\n",
    "                final_predictions.append(2 if pred_2_3[0] * heuristics[6]> pred_2_3[1] * heuristics[7] else 3)\n",
    "    \n",
    "    report = classification_report(true_labels, final_predictions, digits=6)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plain\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.852071  0.900000  0.875380       160\n",
      "           1   0.588235  0.555556  0.571429        54\n",
      "           2   0.625000  0.571429  0.597015        35\n",
      "           3   0.677419  0.600000  0.636364        35\n",
      "           4   0.642857  0.692308  0.666667        13\n",
      "\n",
      "    accuracy                       0.754209       297\n",
      "   macro avg   0.677117  0.663858  0.669371       297\n",
      "weighted avg   0.747602  0.754209  0.750010       297\n",
      "\n",
      "<=========================================================================>\n",
      "heuristics precision\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.852071  0.900000  0.875380       160\n",
      "           1   0.617021  0.537037  0.574257        54\n",
      "           2   0.600000  0.600000  0.600000        35\n",
      "           3   0.687500  0.628571  0.656716        35\n",
      "           4   0.642857  0.692308  0.666667        13\n",
      "\n",
      "    accuracy                       0.757576       297\n",
      "   macro avg   0.679890  0.671583  0.674604       297\n",
      "weighted avg   0.751078  0.757576  0.753274       297\n",
      "\n",
      "<=========================================================================>\n",
      "heuristics recall\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.840000  0.918750  0.877612       160\n",
      "           1   0.580000  0.537037  0.557692        54\n",
      "           2   0.645161  0.571429  0.606061        35\n",
      "           3   0.807692  0.600000  0.688525        35\n",
      "           4   0.600000  0.692308  0.642857        13\n",
      "\n",
      "    accuracy                       0.760943       297\n",
      "   macro avg   0.694571  0.663905  0.674549       297\n",
      "weighted avg   0.755454  0.760943  0.754885       297\n",
      "\n",
      "<=========================================================================>\n",
      "heuristics f1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.852941  0.906250  0.878788       160\n",
      "           1   0.588235  0.555556  0.571429        54\n",
      "           2   0.625000  0.571429  0.597015        35\n",
      "           3   0.700000  0.600000  0.646154        35\n",
      "           4   0.642857  0.692308  0.666667        13\n",
      "\n",
      "    accuracy                       0.757576       297\n",
      "   macro avg   0.681807  0.665108  0.672010       297\n",
      "weighted avg   0.750732  0.757576  0.752999       297\n",
      "\n",
      "<=========================================================================>\n",
      "heuristics all\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.844828  0.918750  0.880240       160\n",
      "           1   0.591837  0.537037  0.563107        54\n",
      "           2   0.625000  0.571429  0.597015        35\n",
      "           3   0.750000  0.600000  0.666667        35\n",
      "           4   0.642857  0.692308  0.666667        13\n",
      "\n",
      "    accuracy                       0.760943       297\n",
      "   macro avg   0.690904  0.663905  0.674739       297\n",
      "weighted avg   0.752908  0.760943  0.754686       297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heuristics_precision = [0.89 , 0.96 , 0.87 , 0.92 ,1.0 , 1.0, 0.86 , 0.86]\n",
    "heuristics_recall = [0.97 , 0.86 , 0.93 , 0.86 ,1.0 , 1.0, 0.86 , 0.86]\n",
    "heuristics_f1 = [0.93 , 0.91 , 0.90 , 0.89 ,1.0 , 1.0, 0.86 , 0.86]\n",
    "\n",
    "heuristics_multiply = [0.802869, 0.751296, 0.728190, 0.704168, 1.0, 1.0, 0.636056, 0.636056]\n",
    "print(\"plain\")\n",
    "predict_all(df, smote_models, smote_scalers, smote_features_dict, input_columns)\n",
    "print(\"<=========================================================================>\")\n",
    "print(\"heuristics precision\")\n",
    "predict_all(df, smote_models, smote_scalers, smote_features_dict, input_columns,heuristics_precision)\n",
    "print(\"<=========================================================================>\")\n",
    "print(\"heuristics recall\")\n",
    "predict_all(df, smote_models, smote_scalers, smote_features_dict, input_columns,heuristics_recall)\n",
    "print(\"<=========================================================================>\")\n",
    "print(\"heuristics f1\")\n",
    "predict_all(df, smote_models, smote_scalers, smote_features_dict, input_columns,heuristics_f1)\n",
    "print(\"<=========================================================================>\")\n",
    "print(\"heuristics all\")\n",
    "predict_all(df, smote_models, smote_scalers, smote_features_dict, input_columns, heuristics_multiply)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plain\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.857143  0.975000  0.912281       160\n",
      "           1   0.789474  0.277778  0.410959        54\n",
      "           2   0.571429  0.685714  0.623377        35\n",
      "           3   0.608696  0.800000  0.691358        35\n",
      "           4   0.625000  0.384615  0.476190        13\n",
      "\n",
      "    accuracy                       0.767677       297\n",
      "   macro avg   0.690348  0.624621  0.622833       297\n",
      "weighted avg   0.771730  0.767677  0.741963       297\n",
      "\n",
      "<=========================================================================>\n",
      "heuristics precision\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.857143  0.975000  0.912281       160\n",
      "           1   0.833333  0.277778  0.416667        54\n",
      "           2   0.581395  0.714286  0.641026        35\n",
      "           3   0.583333  0.800000  0.674699        35\n",
      "           4   0.500000  0.230769  0.315789        13\n",
      "\n",
      "    accuracy                       0.764310       297\n",
      "   macro avg   0.671041  0.599567  0.592092       297\n",
      "weighted avg   0.772419  0.764310  0.736096       297\n",
      "\n",
      "<=========================================================================>\n",
      "heuristics recall\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.857143  0.975000  0.912281       160\n",
      "           1   0.703704  0.351852  0.469136        54\n",
      "           2   0.605263  0.657143  0.630137        35\n",
      "           3   0.650000  0.742857  0.693333        35\n",
      "           4   0.600000  0.461538  0.521739        13\n",
      "\n",
      "    accuracy                       0.774411       297\n",
      "   macro avg   0.683222  0.637678  0.645325       297\n",
      "weighted avg   0.763896  0.774411  0.755563       297\n",
      "\n",
      "<=========================================================================>\n",
      "heuristics f1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.857143  0.975000  0.912281       160\n",
      "           1   0.750000  0.277778  0.405405        54\n",
      "           2   0.585366  0.685714  0.631579        35\n",
      "           3   0.608696  0.800000  0.691358        35\n",
      "           4   0.625000  0.384615  0.476190        13\n",
      "\n",
      "    accuracy                       0.767677       297\n",
      "   macro avg   0.685241  0.624621  0.623363       297\n",
      "weighted avg   0.766195  0.767677  0.741919       297\n",
      "\n",
      "<=========================================================================>\n",
      "heuristics all\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.853261  0.981250  0.912791       160\n",
      "           1   0.750000  0.277778  0.405405        54\n",
      "           2   0.585366  0.685714  0.631579        35\n",
      "           3   0.627907  0.771429  0.692308        35\n",
      "           4   0.555556  0.384615  0.454545        13\n",
      "\n",
      "    accuracy                       0.767677       297\n",
      "   macro avg   0.674418  0.620157  0.619326       297\n",
      "weighted avg   0.763328  0.767677  0.741359       297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heuristics_precision =[0.937500 , 0.928571 , 0.812500 , 0.916667 , 1.0 , 1.0 , 0.857143 , 0.857143]\n",
    "heuristics_recall =[0.937500 , 0.928571 , 0.928571 , 0.785714 , 1.0 , 1.0 , 0.857143 , 0.857143]\n",
    "heuristics_f1 =[0.937500 , 0.928571 , 0.866667 , 0.846154 , 1.0 , 1.0 , 0.857143 , 0.857143]\n",
    "heuristics_multiply = [0.823975, 0.800655 , 0.653869, 0.609432, 1.0, 1.0, 0.629738, 0.629738]\n",
    "\n",
    "print(\"plain\")\n",
    "predict_all(df, adasyn_models, adasyn_scalers, adasyn_features_dict, input_columns)\n",
    "print(\"<=========================================================================>\")\n",
    "print(\"heuristics precision\")\n",
    "predict_all(df, adasyn_models, adasyn_scalers, adasyn_features_dict, input_columns,heuristics_precision)\n",
    "print(\"<=========================================================================>\")\n",
    "print(\"heuristics recall\")\n",
    "predict_all(df, adasyn_models, adasyn_scalers, adasyn_features_dict, input_columns,heuristics_recall)\n",
    "print(\"<=========================================================================>\")\n",
    "print(\"heuristics f1\")\n",
    "predict_all(df, adasyn_models, adasyn_scalers, adasyn_features_dict, input_columns,heuristics_f1)\n",
    "print(\"<=========================================================================>\")\n",
    "print(\"heuristics all\")\n",
    "predict_all(df, adasyn_models, adasyn_scalers, adasyn_features_dict, input_columns, heuristics_multiply)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plain\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.824561  0.881250  0.851964       160\n",
      "           1   0.630435  0.537037  0.580000        54\n",
      "           2   0.758621  0.628571  0.687500        35\n",
      "           3   0.641026  0.714286  0.675676        35\n",
      "           4   0.916667  0.846154  0.880000        13\n",
      "\n",
      "    accuracy                       0.767677       297\n",
      "   macro avg   0.754262  0.721460  0.735028       297\n",
      "weighted avg   0.763898  0.767677  0.763587       297\n",
      "\n",
      "<=========================================================================>\n",
      "heuristics precision\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.829412  0.881250  0.854545       160\n",
      "           1   0.645833  0.574074  0.607843        54\n",
      "           2   0.685714  0.685714  0.685714        35\n",
      "           3   0.677419  0.600000  0.636364        35\n",
      "           4   0.846154  0.846154  0.846154        13\n",
      "\n",
      "    accuracy                       0.767677       297\n",
      "   macro avg   0.736907  0.717438  0.726124       297\n",
      "weighted avg   0.761921  0.767677  0.763716       297\n",
      "\n",
      "<=========================================================================>\n",
      "heuristics recall\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.816092  0.887500  0.850299       160\n",
      "           1   0.634146  0.481481  0.547368        54\n",
      "           2   0.700000  0.600000  0.646154        35\n",
      "           3   0.609756  0.714286  0.657895        35\n",
      "           4   1.000000  0.846154  0.916667        13\n",
      "\n",
      "    accuracy                       0.757576       297\n",
      "   macro avg   0.751999  0.705884  0.723677       297\n",
      "weighted avg   0.753064  0.757576  0.751394       297\n",
      "\n",
      "<=========================================================================>\n",
      "heuristics f1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.824561  0.881250  0.851964       160\n",
      "           1   0.644444  0.537037  0.585859        54\n",
      "           2   0.766667  0.657143  0.707692        35\n",
      "           3   0.641026  0.714286  0.675676        35\n",
      "           4   0.916667  0.846154  0.880000        13\n",
      "\n",
      "    accuracy                       0.771044       297\n",
      "   macro avg   0.758673  0.727174  0.740238       297\n",
      "weighted avg   0.767393  0.771044  0.767032       297\n",
      "\n",
      "<=========================================================================>\n",
      "heuristics all\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.816092  0.887500  0.850299       160\n",
      "           1   0.642857  0.500000  0.562500        54\n",
      "           2   0.733333  0.628571  0.676923        35\n",
      "           3   0.615385  0.685714  0.648649        35\n",
      "           4   0.916667  0.846154  0.880000        13\n",
      "\n",
      "    accuracy                       0.760943       297\n",
      "   macro avg   0.744867  0.709588  0.723674       297\n",
      "weighted avg   0.755592  0.760943  0.755077       297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heuristics_precision =[0.909091 , 0.925926 , 0.923077 , 0.866667 , 1.0 , 1.0 , 1.0 , 0.777778]\n",
    "heuristics_recall =[0.937500 , 0.892857 , 0.857143 , 0.928571 , 1.0 , 1.0 , 0.714286 , 1.0]\n",
    "heuristics_f1 =[0.923077  , 0.909091  , 0.888889  , 0.896552 , 1.0 , 1.0 , 0.833333 , 0.875000 ]\n",
    "heuristics_multiply = [0.786713, 0.751563, 0.703297, 0.721511 , 1.0, 1.0, 0.595238, 0.680556]\n",
    "\n",
    "\n",
    "print(\"plain\")\n",
    "predict_all(df, smote_tomek_models, smote_tomek_scalers, smote_tomek_features_dict, input_columns)\n",
    "print(\"<=========================================================================>\")\n",
    "print(\"heuristics precision\")\n",
    "predict_all(df, smote_tomek_models, smote_tomek_scalers, smote_tomek_features_dict, input_columns,heuristics_precision)\n",
    "print(\"<=========================================================================>\")\n",
    "print(\"heuristics recall\")\n",
    "predict_all(df, smote_tomek_models, smote_tomek_scalers, smote_tomek_features_dict, input_columns,heuristics_recall)\n",
    "print(\"<=========================================================================>\")\n",
    "print(\"heuristics f1\")\n",
    "predict_all(df, smote_tomek_models, smote_tomek_scalers, smote_tomek_features_dict, input_columns,heuristics_f1)\n",
    "print(\"<=========================================================================>\")\n",
    "print(\"heuristics all\")\n",
    "predict_all(df, smote_tomek_models, smote_tomek_scalers, smote_tomek_features_dict, input_columns, heuristics_multiply)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plain\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.868263  0.906250  0.886850       160\n",
      "           1   0.520833  0.462963  0.490196        54\n",
      "           2   0.475000  0.542857  0.506667        35\n",
      "           3   0.500000  0.485714  0.492754        35\n",
      "           4   0.875000  0.538462  0.666667        13\n",
      "\n",
      "    accuracy                       0.717172       297\n",
      "   macro avg   0.647819  0.587249  0.608627       297\n",
      "weighted avg   0.715647  0.717172  0.713848       297\n",
      "\n",
      "<=========================================================================>\n",
      "heuristics precision\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.888889  0.900000  0.894410       160\n",
      "           1   0.476190  0.555556  0.512821        54\n",
      "           2   0.500000  0.571429  0.533333        35\n",
      "           3   0.500000  0.342857  0.406780        35\n",
      "           4   0.875000  0.538462  0.666667        13\n",
      "\n",
      "    accuracy                       0.717172       297\n",
      "   macro avg   0.648016  0.581661  0.602802       297\n",
      "weighted avg   0.721588  0.717172  0.715046       297\n",
      "\n",
      "<=========================================================================>\n",
      "heuristics recall\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.842697  0.937500  0.887574       160\n",
      "           1   0.567568  0.388889  0.461538        54\n",
      "           2   0.419355  0.371429  0.393939        35\n",
      "           3   0.444444  0.571429  0.500000        35\n",
      "           4   0.833333  0.384615  0.526316        13\n",
      "\n",
      "    accuracy                       0.703704       297\n",
      "   macro avg   0.621479  0.530772  0.553874       297\n",
      "weighted avg   0.695442  0.703704  0.690454       297\n",
      "\n",
      "<=========================================================================>\n",
      "heuristics f1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.852941  0.906250  0.878788       160\n",
      "           1   0.511111  0.425926  0.464646        54\n",
      "           2   0.450000  0.514286  0.480000        35\n",
      "           3   0.500000  0.485714  0.492754        35\n",
      "           4   0.875000  0.538462  0.666667        13\n",
      "\n",
      "    accuracy                       0.707071       297\n",
      "   macro avg   0.637810  0.574127  0.596571       297\n",
      "weighted avg   0.702679  0.707071  0.701717       297\n",
      "\n",
      "<=========================================================================>\n",
      "heuristics all\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.843931  0.912500  0.876877       160\n",
      "           1   0.523810  0.407407  0.458333        54\n",
      "           2   0.447368  0.485714  0.465753        35\n",
      "           3   0.486486  0.514286  0.500000        35\n",
      "           4   0.857143  0.461538  0.600000        13\n",
      "\n",
      "    accuracy                       0.703704       297\n",
      "   macro avg   0.631748  0.556289  0.580193       297\n",
      "weighted avg   0.697449  0.703704  0.695797       297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heuristics_precision =[0.885714 , 0.960000 , 0.916667 , 0.812500  , 1.0 , 1.0 , 1.0 , 0.777778]\n",
    "heuristics_recall =[0.968750 , 0.857143 , 0.785714 , 0.928571  , 1.0 , 1.0 , 0.714286 , 1.0]\n",
    "heuristics_f1 =[0.925373  , 0.905660   , 0.846154   , 0.866667 , 1.0 , 1.0 , 0.833333 , 0.875000 ]\n",
    "heuristics_multiply = [0.794003, 0.745229, 0.609432, 0.653869, 1.0, 1.0, 0.595238, 0.680556]\n",
    "\n",
    "print(\"plain\")\n",
    "predict_all(df, kmeans_smote_models, kmeans_smote_scalers, kmeans_smote_features_dict, input_columns)\n",
    "print(\"<=========================================================================>\")\n",
    "print(\"heuristics precision\")\n",
    "predict_all(df, kmeans_smote_models, kmeans_smote_scalers, kmeans_smote_features_dict, input_columns,heuristics_precision)\n",
    "print(\"<=========================================================================>\")\n",
    "print(\"heuristics recall\")\n",
    "predict_all(df, kmeans_smote_models, kmeans_smote_scalers, kmeans_smote_features_dict, input_columns,heuristics_recall)\n",
    "print(\"<=========================================================================>\")\n",
    "print(\"heuristics f1\")\n",
    "predict_all(df, kmeans_smote_models, kmeans_smote_scalers, kmeans_smote_features_dict, input_columns,heuristics_f1)\n",
    "print(\"<=========================================================================>\")\n",
    "print(\"heuristics all\")\n",
    "predict_all(df, kmeans_smote_models, kmeans_smote_scalers, kmeans_smote_features_dict, input_columns, heuristics_multiply)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plain\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.894737  0.956250  0.924471       160\n",
      "           1   0.564103  0.407407  0.473118        54\n",
      "           2   0.406250  0.371429  0.388060        35\n",
      "           3   0.400000  0.457143  0.426667        35\n",
      "           4   0.333333  0.384615  0.357143        13\n",
      "\n",
      "    accuracy                       0.703704       297\n",
      "   macro avg   0.519685  0.515369  0.513892       297\n",
      "weighted avg   0.694180  0.703704  0.695697       297\n",
      "\n",
      "<=========================================================================>\n",
      "heuristics precision\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.898204  0.937500  0.917431       160\n",
      "           1   0.560976  0.425926  0.484211        54\n",
      "           2   0.384615  0.285714  0.327869        35\n",
      "           3   0.382979  0.514286  0.439024        35\n",
      "           4   0.312500  0.384615  0.344828        13\n",
      "\n",
      "    accuracy                       0.693603       297\n",
      "   macro avg   0.507855  0.509608  0.502673       297\n",
      "weighted avg   0.690012  0.693603  0.687745       297\n",
      "\n",
      "<=========================================================================>\n",
      "heuristics recall\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.850829  0.962500  0.903226       160\n",
      "           1   0.384615  0.185185  0.250000        54\n",
      "           2   0.320000  0.457143  0.376471        35\n",
      "           3   0.363636  0.342857  0.352941        35\n",
      "           4   0.428571  0.230769  0.300000        13\n",
      "\n",
      "    accuracy                       0.656566       297\n",
      "   macro avg   0.469530  0.435691  0.436528       297\n",
      "weighted avg   0.627611  0.656566  0.631130       297\n",
      "\n",
      "<=========================================================================>\n",
      "heuristics f1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.889535  0.956250  0.921687       160\n",
      "           1   0.558140  0.444444  0.494845        54\n",
      "           2   0.368421  0.400000  0.383562        35\n",
      "           3   0.411765  0.400000  0.405797        35\n",
      "           4   0.400000  0.307692  0.347826        13\n",
      "\n",
      "    accuracy                       0.703704       297\n",
      "   macro avg   0.525572  0.501677  0.510743       297\n",
      "weighted avg   0.690140  0.703704  0.694750       297\n",
      "\n",
      "<=========================================================================>\n",
      "heuristics all\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.874286  0.956250  0.913433       160\n",
      "           1   0.468750  0.277778  0.348837        54\n",
      "           2   0.347826  0.457143  0.395062        35\n",
      "           3   0.378378  0.400000  0.388889        35\n",
      "           4   0.428571  0.230769  0.300000        13\n",
      "\n",
      "    accuracy                       0.676768       297\n",
      "   macro avg   0.499562  0.464388  0.469244       297\n",
      "weighted avg   0.660562  0.676768  0.661026       297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heuristics_precision =[0.86 , 0.960000 , 0.86 , 0.86  , 0.92 , 1.0 , 0.78 , 1.0]\n",
    "heuristics_recall =[0.97 , 0.82 , 0.86 , 0.96  , 1.0 , 0.67 , 1.0 , 0.71]\n",
    "heuristics_f1 =[0.91  , 0.88   , 0.86   , 0.86 , 0.96 , 0.8 , 0.88 , 0.83 ]\n",
    "heuristics_multiply = [0.7591220000000001, 0.6927359999999999, 0.636056, 0.710016, 0.8832, 0.536, 0.6864, 0.5892999999999999]\n",
    "\n",
    "\n",
    "print(\"plain\")\n",
    "predict_all(df, raw_models, raw_scalers, raw_features_dict, input_columns)\n",
    "print(\"<=========================================================================>\")\n",
    "print(\"heuristics precision\")\n",
    "predict_all(df, raw_models, raw_scalers, raw_features_dict, input_columns,heuristics_precision)\n",
    "print(\"<=========================================================================>\")\n",
    "print(\"heuristics recall\")\n",
    "predict_all(df, raw_models, raw_scalers, raw_features_dict, input_columns,heuristics_recall)\n",
    "print(\"<=========================================================================>\")\n",
    "print(\"heuristics f1\")\n",
    "predict_all(df, raw_models, raw_scalers, raw_features_dict, input_columns,heuristics_f1)\n",
    "print(\"<=========================================================================>\")\n",
    "print(\"heuristics all\")\n",
    "predict_all(df, raw_models, raw_scalers, raw_features_dict, input_columns, heuristics_multiply)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7591220000000001, 0.6927359999999999, 0.636056, 0.710016, 0.8832, 0.536, 0.6864, 0.5892999999999999]\n"
     ]
    }
   ],
   "source": [
    "result = [a * b * c for a, b, c in zip(heuristics_f1, heuristics_recall, heuristics_precision)]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
